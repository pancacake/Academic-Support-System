import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional
import importlib.util

# å¯¼å…¥é›†ä¸­ç®¡ç†çš„æç¤ºè¯
try:
    from prompts import NOTE_GENERATION_SYSTEM_PROMPT
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯
    NOTE_GENERATION_SYSTEM_PROMPT = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯ç¬”è®°ç”ŸæˆåŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆç»“æ„åŒ–ã€æ˜“äºç†è§£çš„å­¦ä¹ ç¬”è®°ã€‚"

# åŠ¨æ€å¯¼å…¥ API å®¢æˆ·ç«¯
def get_api_client():
    """åŠ¨æ€å¯¼å…¥APIå®¢æˆ·ç«¯"""
    try:
        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
        project_root = Path(__file__).parent.parent.parent
        sys.path.append(str(project_root))
        
        from api_client import APIClient
        from config import API_KEY, BASE_URL, DEFAULT_MODEL
        
        return APIClient(
            api_key=API_KEY,
            base_url=BASE_URL,
            default_model=DEFAULT_MODEL
        )
    except ImportError as e:
        print(f"Warning: APIé…ç½®æ–‡ä»¶æœªæ‰¾åˆ° - {e}")
        return None
    except Exception as e:
        print(f"Warning: APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ - {e}")
        return None

class NoteGenerator:
    """
    Djangoç‰ˆæœ¬çš„ç¬”è®°ç”Ÿæˆå™¨
    æ ¹æ®JSONæ ¼å¼çš„æ–‡æœ¬å†…å®¹ï¼Œé€šè¿‡APIClientç”Ÿæˆç»“æ„åŒ–çš„ç¬”è®°
    """

    # ä½¿ç”¨é›†ä¸­ç®¡ç†çš„ç³»ç»Ÿæç¤ºè¯
    SYSTEM_PROMPT = NOTE_GENERATION_SYSTEM_PROMPT

    def __init__(self):
        """åˆå§‹åŒ–ç¬”è®°ç”Ÿæˆå™¨"""
        self.api_client = get_api_client()

    def generate_notes_streaming(self, json_file_path: str, output_dir: str = None) -> Dict[str, Any]:
        """æµå¼ç”Ÿæˆç¬”è®°ï¼Œè¿”å›ç”Ÿæˆå™¨ç”¨äºå®æ—¶ä¼ è¾“"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
            if output_dir is None:
                output_dir = "media/output"  # é»˜è®¤è·¯å¾„ï¼Œä½†åº”è¯¥ç”±è°ƒç”¨è€…æŒ‡å®šç”¨æˆ·ç‰¹å®šè·¯å¾„

            notes_output_path = Path(output_dir) / timestamp

            notes_output_path.mkdir(parents=True, exist_ok=True)
            
            # æå–æ–‡æœ¬å†…å®¹å’Œå›¾ç‰‡ä¿¡æ¯
            extracted_data = self._extract_text_from_json(json_file_path, str(notes_output_path))
            text_content = extracted_data["text_content"]
            images_info = extracted_data["images_info"]
            
            if not text_content.strip():
                yield {"type": "error", "content": "JSONæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹"}
                return
            
            # æ„å»ºå›¾ç‰‡ä¿¡æ¯éƒ¨åˆ†
            images_section = ""
            if images_info:
                images_section = "\n\nå¯ç”¨å›¾ç‰‡ä¿¡æ¯ï¼š\n"
                for i, img in enumerate(images_info, 1):
                    images_section += f"{i}. é¡µé¢{img['page']} - è·¯å¾„: {img['rel_path']}\n"
                    images_section += f"   æè¿°: {img['caption']}\n"
            
            prompt = self.SYSTEM_PROMPT + images_section + "\n\næ–‡æœ¬å†…å®¹:\n" + text_content
            
            # ä¿å­˜æå–çš„æ–‡æœ¬å†…å®¹å’Œæç¤ºè¯
            init_path = notes_output_path / "extracted_content.txt"
            with open(init_path, "w", encoding="utf-8") as f:
                f.write(text_content)
            
            prompt_path = notes_output_path / "full_prompt.txt"
            with open(prompt_path, "w", encoding="utf-8") as f:
                f.write(prompt)
            
            # æ£€æŸ¥APIå®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨
            if not self.api_client:
                yield {"type": "error", "content": "APIå®¢æˆ·ç«¯ä¸å¯ç”¨"}
                return
            
            # æµå¼ç”Ÿæˆ
            md_file_path = notes_output_path / "notes.md"
            
            yield {"type": "start", "content": "å¼€å§‹ç”Ÿæˆç¬”è®°..."}
            
            try:
                stream = self.api_client.client.chat.completions.create(
                    model=self.api_client.default_model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=50000,
                    temperature=0.5,
                    timeout=300,  # å¢åŠ åˆ°5åˆ†é’Ÿ
                    stream=True,
                    stream_options={"include_usage": True}
                )
                
                with open(md_file_path, "w", encoding="utf-8") as f:
                    for chunk in stream:
                        content_piece = None
                        if hasattr(chunk, "choices") and chunk.choices:
                            delta = chunk.choices[0].delta
                            if hasattr(delta, "content") and delta.content is not None:
                                content_piece = delta.content
                            elif isinstance(delta, dict) and "content" in delta and delta["content"] is not None:
                                content_piece = delta["content"]
                        
                        if content_piece:
                            f.write(content_piece)
                            f.flush()
                            yield {"type": "content", "content": content_piece}
                
                # ç”Ÿæˆç›®å½•æ–‡ä»¶
                toc_content = self._generate_table_of_contents(str(md_file_path))
                toc_file_path = notes_output_path / "contents.md"
                with open(toc_file_path, "w", encoding="utf-8") as f:
                    f.write(toc_content)

                yield {
                    "type": "complete",
                    "content": "ç¬”è®°ç”Ÿæˆå®Œæˆï¼",
                    "file_path": str(md_file_path),
                    "output_dir": str(notes_output_path),
                    "toc_file_path": str(toc_file_path),
                    "toc_content": toc_content
                }
                
            except Exception as e:
                yield {"type": "error", "content": f"APIè°ƒç”¨å¤±è´¥: {str(e)}"}
                
        except Exception as e:
            yield {"type": "error", "content": f"ç¬”è®°ç”Ÿæˆå¤±è´¥: {str(e)}"}

    def _generate_table_of_contents(self, md_file_path: str) -> str:
        """ä»Markdownæ–‡ä»¶ç”Ÿæˆç›®å½•"""
        try:
            # å°è¯•å¤šç§ç¼–ç æ–¹å¼è¯»å–æ–‡ä»¶
            content = None
            encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'latin1']

            for encoding in encodings:
                try:
                    with open(md_file_path, 'r', encoding=encoding, errors='ignore') as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue

            if content is None:
                return '# ğŸ“š ç¬”è®°ç›®å½•\n\næ— æ³•è¯»å–æ–‡ä»¶å†…å®¹'

            lines = content.split('\n')
            toc_lines = ['# ğŸ“š ç¬”è®°ç›®å½•\n']

            for line in lines:
                line = line.strip()
                if not line.startswith('#'):
                    continue

                # è®¡ç®—æ ‡é¢˜çº§åˆ«
                level = 0
                for char in line:
                    if char == '#':
                        level += 1
                    else:
                        break

                if level > 6 or level == 0:  # Markdownæœ€å¤šæ”¯æŒ6çº§æ ‡é¢˜
                    continue

                # æå–æ ‡é¢˜æ–‡æœ¬
                title = line[level:].strip()
                if not title:
                    continue

                # æ¸…ç†æ ‡é¢˜æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½çš„ç‰¹æ®Šå­—ç¬¦
                title = ''.join(char for char in title if ord(char) < 65536)  # ç§»é™¤è¶…å‡ºBMPçš„å­—ç¬¦

                # ç”Ÿæˆç›®å½•é¡¹ - ä½¿ç”¨HTMLæ ¼å¼ä»¥ä¾¿æ›´å¥½çš„æ ·å¼æ§åˆ¶
                if level == 1:
                    toc_lines.append(f'<div class="toc-level-1">ğŸ“– {title}</div>')
                elif level == 2:
                    toc_lines.append(f'<div class="toc-level-2">ğŸ“„ {title}</div>')
                elif level == 3:
                    toc_lines.append(f'<div class="toc-level-3">ğŸ“ {title}</div>')
                else:
                    indent = '&nbsp;&nbsp;&nbsp;&nbsp;' * (level - 1)
                    toc_lines.append(f'<div class="toc-level-{level}">{indent}â€¢ {title}</div>')

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ ‡é¢˜
            if len(toc_lines) == 1:
                toc_lines.append('- æœªæ‰¾åˆ°æ ‡é¢˜å†…å®¹')

            # æ·»åŠ ç”Ÿæˆæ—¶é—´
            from datetime import datetime
            toc_lines.append(f'\n---\n*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*')

            return '\n'.join(toc_lines)

        except Exception as e:
            return f'# ğŸ“š ç¬”è®°ç›®å½•\n\nç”Ÿæˆç›®å½•æ—¶å‡ºé”™: {str(e)}'

    def _extract_text_from_json(self, json_file_path: str, md_dir: str = None) -> Dict[str, Any]:
        """ä»JSONæ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹å’Œå›¾ç‰‡ä¿¡æ¯"""
        try:
            with open(json_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            if not isinstance(data, list):
                raise ValueError("JSONæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”è¯¥æ˜¯ä¸€ä¸ªæ•°ç»„")

            pages_text: Dict[str, List[str]] = {}
            pages_figures: Dict[str, List[str]] = {}
            images_info: List[Dict[str, str]] = []

            for item in data:
                if not isinstance(item, dict):
                    continue

                if item.get("type") == "text" and "content" in item:
                    page = str(item.get("page", "unknown"))
                    content = item.get("content", "").strip()
                    if content:
                        if page not in pages_text:
                            pages_text[page] = []
                        pages_text[page].append(content)

                elif item.get("type") == "figure" and "path" in item:
                    page = str(item.get("page", "unknown"))
                    abs_path = item.get("path", "")
                    caption = item.get("caption", "")

                    # ç”Ÿæˆç›¸å¯¹äºmdæ–‡ä»¶çš„è·¯å¾„
                    rel_path = abs_path
                    if md_dir and os.path.isabs(abs_path):
                        rel_path = os.path.relpath(abs_path, md_dir).replace("\\", "/")

                    # å¯¹äºç”¨æˆ·ç‰¹å®šè·¯å¾„ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                    # å¦‚æœè·¯å¾„åŒ…å« media/ç”¨æˆ·ID/uploadsï¼Œè½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                    if "media" in rel_path and "uploads" in rel_path:
                        # æå– uploads åé¢çš„éƒ¨åˆ†
                        uploads_index = rel_path.find("uploads")
                        if uploads_index != -1:
                            # ä» uploads å¼€å§‹çš„è·¯å¾„éƒ¨åˆ†
                            uploads_part = rel_path[uploads_index:]
                            # ç”Ÿæˆç›¸å¯¹äºç¬”è®°è¾“å‡ºç›®å½•çš„è·¯å¾„
                            rel_path = f"../../{uploads_part}"

                    images_info.append({"page": page, "abs_path": abs_path, "rel_path": rel_path, "caption": caption})
                    if page not in pages_figures:
                        pages_figures[page] = []
                    pages_figures[page].append(f"[å›¾ç‰‡] è·¯å¾„: {rel_path}\næè¿°: {caption}")

            def page_sort_key(page_str):
                try:
                    return int(page_str)
                except (ValueError, TypeError):
                    return float('inf')

            organized_text = []
            all_pages = set(list(pages_text.keys()) + list(pages_figures.keys()))
            for page in sorted(all_pages, key=page_sort_key):
                page_content = "\n".join(pages_text.get(page, []))
                page_figures = "\n".join(pages_figures.get(page, []))
                if page_content:
                    page_content = page_content.strip()
                if page_figures:
                    page_figures = page_figures.strip()
                page_sections = []
                if page_content:
                    page_sections.append(page_content)
                if page_figures:
                    page_sections.append(page_figures)
                if page_sections:
                    page_text = f"=== ç¬¬{page}é¡µ ===\n" + "\n\n".join(page_sections)
                    organized_text.append(page_text)

            return {
                "text_content": "\n\n".join(organized_text),
                "images_info": images_info
            }
        except Exception as e:
            raise e
